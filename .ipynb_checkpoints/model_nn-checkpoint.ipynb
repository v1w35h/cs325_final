{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea83d82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "from PIL import Image, ImageOps, ImageFilter \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e8aa53b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_num_threads(os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bff6194d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DogBreedDataset(Dataset):\n",
    "    def __init__(self, label_df, img_dir, labels, transform=None): \n",
    "        self.labels_df = label_df.reset_index(drop=True)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        # Dict mapping 'breed' to index, model will operate on integers and we will convert back to breeds \n",
    "        self.classes = labels\n",
    "\n",
    "    def __len__(self): \n",
    "        return len(self.labels_df)\n",
    "    \n",
    "    def __getitem__(self, index): \n",
    "        row = self.labels_df.iloc[index]\n",
    "        path = os.path.join(self.img_dir, row[\"id\"]+ \".jpg\")\n",
    "        img = Image.open(path)\n",
    "        img = img.convert(\"RGB\")\n",
    "\n",
    "        if self.transform: \n",
    "            img = self.transform(img)\n",
    "\n",
    "        label = self.classes[row['breed']]\n",
    "\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d4bc3886",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(\"data/labels.csv\")\n",
    "breeds = labels['breed'].unique() \n",
    "\n",
    "# Dict mapping 'breed' to index, model will operate on integers and we will convert back to breeds \n",
    "classes = {b: i for i, b in enumerate(breeds)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "36b28e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.RandomHorizontalFlip(), \n",
    "    transforms.RandomResizedCrop(224, scale = (0.8, 1.0)),\n",
    "    transforms.RandomRotation(15), \n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3), \n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1e0b1237",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DogBreedDataset(labels, \"data/train\", classes, train_transforms)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e21ce305",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e7170222",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(dataset.labels_df, \n",
    "                                    test_size=0.2, \n",
    "                                    stratify=dataset.labels_df['breed'])\n",
    "\n",
    "train_df.to_csv(\"train_split.csv\", index=False)\n",
    "val_df.to_csv(\"val_split.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "958187f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DogBreedDataset(\n",
    "    label_df=train_df,\n",
    "    img_dir ='data/train',\n",
    "    labels = classes,\n",
    "    transform=train_transforms\n",
    ")\n",
    "\n",
    "val_dataset = DogBreedDataset(\n",
    "    label_df = val_df,\n",
    "    img_dir ='data/train',\n",
    "    labels = classes, \n",
    "    transform=val_transforms\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b0866cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'boston_bull': 0, 'dingo': 1, 'pekinese': 2, 'bluetick': 3, 'golden_retriever': 4, 'bedlington_terrier': 5, 'borzoi': 6, 'basenji': 7, 'scottish_deerhound': 8, 'shetland_sheepdog': 9, 'walker_hound': 10, 'maltese_dog': 11, 'norfolk_terrier': 12, 'african_hunting_dog': 13, 'wire-haired_fox_terrier': 14, 'redbone': 15, 'lakeland_terrier': 16, 'boxer': 17, 'doberman': 18, 'otterhound': 19, 'standard_schnauzer': 20, 'irish_water_spaniel': 21, 'black-and-tan_coonhound': 22, 'cairn': 23, 'affenpinscher': 24, 'labrador_retriever': 25, 'ibizan_hound': 26, 'english_setter': 27, 'weimaraner': 28, 'giant_schnauzer': 29, 'groenendael': 30, 'dhole': 31, 'toy_poodle': 32, 'border_terrier': 33, 'tibetan_terrier': 34, 'norwegian_elkhound': 35, 'shih-tzu': 36, 'irish_terrier': 37, 'kuvasz': 38, 'german_shepherd': 39, 'greater_swiss_mountain_dog': 40, 'basset': 41, 'australian_terrier': 42, 'schipperke': 43, 'rhodesian_ridgeback': 44, 'irish_setter': 45, 'appenzeller': 46, 'bloodhound': 47, 'samoyed': 48, 'miniature_schnauzer': 49, 'brittany_spaniel': 50, 'kelpie': 51, 'papillon': 52, 'border_collie': 53, 'entlebucher': 54, 'collie': 55, 'malamute': 56, 'welsh_springer_spaniel': 57, 'chihuahua': 58, 'saluki': 59, 'pug': 60, 'malinois': 61, 'komondor': 62, 'airedale': 63, 'leonberg': 64, 'mexican_hairless': 65, 'bull_mastiff': 66, 'bernese_mountain_dog': 67, 'american_staffordshire_terrier': 68, 'lhasa': 69, 'cardigan': 70, 'italian_greyhound': 71, 'clumber': 72, 'scotch_terrier': 73, 'afghan_hound': 74, 'old_english_sheepdog': 75, 'saint_bernard': 76, 'miniature_pinscher': 77, 'eskimo_dog': 78, 'irish_wolfhound': 79, 'brabancon_griffon': 80, 'toy_terrier': 81, 'chow': 82, 'flat-coated_retriever': 83, 'norwich_terrier': 84, 'soft-coated_wheaten_terrier': 85, 'staffordshire_bullterrier': 86, 'english_foxhound': 87, 'gordon_setter': 88, 'siberian_husky': 89, 'newfoundland': 90, 'briard': 91, 'chesapeake_bay_retriever': 92, 'dandie_dinmont': 93, 'great_pyrenees': 94, 'beagle': 95, 'vizsla': 96, 'west_highland_white_terrier': 97, 'kerry_blue_terrier': 98, 'whippet': 99, 'sealyham_terrier': 100, 'standard_poodle': 101, 'keeshond': 102, 'japanese_spaniel': 103, 'miniature_poodle': 104, 'pomeranian': 105, 'curly-coated_retriever': 106, 'yorkshire_terrier': 107, 'pembroke': 108, 'great_dane': 109, 'blenheim_spaniel': 110, 'silky_terrier': 111, 'sussex_spaniel': 112, 'german_short-haired_pointer': 113, 'french_bulldog': 114, 'bouvier_des_flandres': 115, 'tibetan_mastiff': 116, 'english_springer': 117, 'cocker_spaniel': 118, 'rottweiler': 119}\n",
      "{'boston_bull': 0, 'dingo': 1, 'pekinese': 2, 'bluetick': 3, 'golden_retriever': 4, 'bedlington_terrier': 5, 'borzoi': 6, 'basenji': 7, 'scottish_deerhound': 8, 'shetland_sheepdog': 9, 'walker_hound': 10, 'maltese_dog': 11, 'norfolk_terrier': 12, 'african_hunting_dog': 13, 'wire-haired_fox_terrier': 14, 'redbone': 15, 'lakeland_terrier': 16, 'boxer': 17, 'doberman': 18, 'otterhound': 19, 'standard_schnauzer': 20, 'irish_water_spaniel': 21, 'black-and-tan_coonhound': 22, 'cairn': 23, 'affenpinscher': 24, 'labrador_retriever': 25, 'ibizan_hound': 26, 'english_setter': 27, 'weimaraner': 28, 'giant_schnauzer': 29, 'groenendael': 30, 'dhole': 31, 'toy_poodle': 32, 'border_terrier': 33, 'tibetan_terrier': 34, 'norwegian_elkhound': 35, 'shih-tzu': 36, 'irish_terrier': 37, 'kuvasz': 38, 'german_shepherd': 39, 'greater_swiss_mountain_dog': 40, 'basset': 41, 'australian_terrier': 42, 'schipperke': 43, 'rhodesian_ridgeback': 44, 'irish_setter': 45, 'appenzeller': 46, 'bloodhound': 47, 'samoyed': 48, 'miniature_schnauzer': 49, 'brittany_spaniel': 50, 'kelpie': 51, 'papillon': 52, 'border_collie': 53, 'entlebucher': 54, 'collie': 55, 'malamute': 56, 'welsh_springer_spaniel': 57, 'chihuahua': 58, 'saluki': 59, 'pug': 60, 'malinois': 61, 'komondor': 62, 'airedale': 63, 'leonberg': 64, 'mexican_hairless': 65, 'bull_mastiff': 66, 'bernese_mountain_dog': 67, 'american_staffordshire_terrier': 68, 'lhasa': 69, 'cardigan': 70, 'italian_greyhound': 71, 'clumber': 72, 'scotch_terrier': 73, 'afghan_hound': 74, 'old_english_sheepdog': 75, 'saint_bernard': 76, 'miniature_pinscher': 77, 'eskimo_dog': 78, 'irish_wolfhound': 79, 'brabancon_griffon': 80, 'toy_terrier': 81, 'chow': 82, 'flat-coated_retriever': 83, 'norwich_terrier': 84, 'soft-coated_wheaten_terrier': 85, 'staffordshire_bullterrier': 86, 'english_foxhound': 87, 'gordon_setter': 88, 'siberian_husky': 89, 'newfoundland': 90, 'briard': 91, 'chesapeake_bay_retriever': 92, 'dandie_dinmont': 93, 'great_pyrenees': 94, 'beagle': 95, 'vizsla': 96, 'west_highland_white_terrier': 97, 'kerry_blue_terrier': 98, 'whippet': 99, 'sealyham_terrier': 100, 'standard_poodle': 101, 'keeshond': 102, 'japanese_spaniel': 103, 'miniature_poodle': 104, 'pomeranian': 105, 'curly-coated_retriever': 106, 'yorkshire_terrier': 107, 'pembroke': 108, 'great_dane': 109, 'blenheim_spaniel': 110, 'silky_terrier': 111, 'sussex_spaniel': 112, 'german_short-haired_pointer': 113, 'french_bulldog': 114, 'bouvier_des_flandres': 115, 'tibetan_mastiff': 116, 'english_springer': 117, 'cocker_spaniel': 118, 'rottweiler': 119}\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.classes)\n",
    "print(val_dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e6eed2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    num_workers=0,  \n",
    "    pin_memory=False\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9f6afe39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking first few dataset items...\n",
      "Item 0: Image shape = torch.Size([3, 224, 224]), Label = 65\n",
      "Item 1: Image shape = torch.Size([3, 224, 224]), Label = 113\n",
      "Item 2: Image shape = torch.Size([3, 224, 224]), Label = 25\n"
     ]
    }
   ],
   "source": [
    "# Test if the dataset itself is working\n",
    "print(\"Checking first few dataset items...\")\n",
    "for i in range(3):\n",
    "    try:\n",
    "        x, y = train_dataset[i]\n",
    "        print(f\"Item {i}: Image shape = {x.shape}, Label = {y}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error at index {i}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eaec52dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=256, out_features=120, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device  = \"cpu\"\n",
    "cnn = models.resnet18(weights=\"IMAGENET1K_V1\")\n",
    "\n",
    "for param in cnn.parameters(): \n",
    "    param.requires_grad = False\n",
    "\n",
    "cnn.fc = nn.Sequential(\n",
    "    nn.Linear(cnn.fc.in_features, 256), \n",
    "    nn.ReLU(), \n",
    "    nn.Dropout(0.5), \n",
    "    nn.Linear(256, num_classes)\n",
    ")\n",
    "\n",
    "cnn=cnn.to(device)\n",
    "print(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5657b1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(cnn.fc.parameters(), lr=1e-4, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f002aaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, criterion, optimizer, num_epochs): \n",
    "    for epoch in range(num_epochs): \n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        for inputs, labels in tqdm(train_loader): \n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, preds = torch.max(outputs,1)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += (preds == labels).sum().item()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_acc = running_corrects / len(train_loader.dataset)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {epoch_loss} | Accuracy: {epoch_acc}\")\n",
    "\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_corrects = 0\n",
    "        with torch.no_grad(): \n",
    "            for inputs, labels in val_loader: \n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                val_corrects += (preds == labels).sum().item()\n",
    "        \n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_acc = val_corrects / len(val_loader.dataset)\n",
    "        print(f\"Validation Loss: {val_loss} | Accuracy: {val_acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a4c5b9a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [02:33<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 | Train Loss: 4.445388658247616 | Accuracy: 0.08499449675920265\n",
      "Validation Loss: 4.108311125235336 | Accuracy: 0.24058679706601466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [02:41<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 | Train Loss: 4.061136771986184 | Accuracy: 0.15115568056744527\n",
      "Validation Loss: 3.597309883532722 | Accuracy: 0.34621026894865525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [03:03<00:00,  1.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 | Train Loss: 3.643144564478733 | Accuracy: 0.21010150421915127\n",
      "Validation Loss: 3.1117800629809316 | Accuracy: 0.4444987775061125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [02:49<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 | Train Loss: 3.28300648063906 | Accuracy: 0.26232114467408585\n",
      "Validation Loss: 2.720641226873421 | Accuracy: 0.5080684596577018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [02:49<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 | Train Loss: 2.978823646467502 | Accuracy: 0.2979087684970038\n",
      "Validation Loss: 2.3912030819284302 | Accuracy: 0.5643031784841076\n"
     ]
    }
   ],
   "source": [
    "train(cnn, train_loader, val_loader, criterion, optimizer, num_epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5222fb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_state = cnn.state_dict()\n",
    "\n",
    "torch.save(model_state, \"model_1.0\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
